{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5684842e",
   "metadata": {},
   "source": [
    "# Large Language Model (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d0d0f",
   "metadata": {},
   "source": [
    "### Generative Search vs Traditional Search\n",
    "\n",
    "Generative search avoids \"keyword\" based SEO optimization. Uses vector embedding to gather context of query.\n",
    "\n",
    "Generative search can provide sourcing information, traditional search returns multiple searches with different sources and possibly different answers.\n",
    "\n",
    "Source referencing is valuable.\n",
    "\n",
    "After a correction, subsequent searches might be updated, as well.\n",
    "\n",
    "Generative search can be poisoned but it learns along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41de23",
   "metadata": {},
   "source": [
    "### Artificial Intelligence\n",
    "\n",
    "#### Self-attention transformer models\n",
    "\n",
    "These factors help us have a model that appears really smart like ChatGPT, Gemini, etc.\n",
    "\n",
    "1. Transformer\n",
    "1. Large-Scale Pretraining\n",
    "1. Fine-tuning\n",
    "1. Compute power\n",
    "1. Optimization\n",
    "1. Contextual Embedding\n",
    "1. Diverse sources of data\n",
    "\n",
    "Backoptimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f93e01",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
